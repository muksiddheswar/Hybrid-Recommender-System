{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySQL connection is closed\n",
      "MySQL connection is closed\n",
      "Previous Model Truncated.\n",
      "Pre-processing....\n",
      "Creating new Model.\n",
      "MySQL connection is closed\n",
      "Exported Content Cosine Similarity Matrix .\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Aug 20 18:00:07 2019\n",
    "\n",
    "@author: smkj33\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Previous Version: \n",
    "    bkp_model_20_Aug.py\n",
    "\n",
    "-- Removing html filter using HTML.parser \n",
    "-- Removing related import statement\n",
    "-- Beautiful soup will be used in it's place'\n",
    "\n",
    "\n",
    "    bkp_model_19_Oct.py \n",
    "    \n",
    "--  Replaced Potter Stemmer with Snowball Stemmer\n",
    "--  Added Cosine similarity with TS-SS.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "# from nltk.stem import PorterStemmer\n",
    "from porter2stemmer import Porter2Stemmer\n",
    "\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "\n",
    "\n",
    "from db_functions import *\n",
    "from queries import *\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#-------------------------------------#\n",
    "# MODEL CREATE HELPER FUNCTIONS\n",
    "#-------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "def filter_html(text):\n",
    "    soup = BeautifulSoup(text, features=\"html5lib\")\n",
    "    # text = re.sub('[^a-z\\s]', '',soup.get_text(separator=' ').lower())\n",
    "    text = soup.get_text(separator=' ')\n",
    "    return text\n",
    "\n",
    "\n",
    "def text_stemmer (txt, stemmer):\n",
    "    token_words=word_tokenize(txt)\n",
    "    stem_sentence=[]\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(stemmer.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)\n",
    "\n",
    "\n",
    "def clean_tags(x):\n",
    "    if isinstance(x, str):\n",
    "        return str.lower(x.replace(\" \", \"\")).replace(\",\",\" \")\n",
    "\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "\n",
    "def theta(cosine_similarity):\n",
    "    sim = np.divide(np.trunc(np.multiply(cosine_similarity, 100000000000000)), 100000000000000)\n",
    "    angles = np.arccos(sim) + math.radians(10)\n",
    "    return angles\n",
    "\n",
    "\n",
    "def magnitude_and_difference(matrix):\n",
    "    magnitude = np.sqrt(matrix.multiply(matrix).sum(1))\n",
    "    magnitude_diff = pairwise_distances(magnitude, metric='manhattan')\n",
    "    return magnitude, magnitude_diff\n",
    "\n",
    "\n",
    "def euclidean(vectors):\n",
    "    distances = euclidean_distances(vectors)\n",
    "    return distances\n",
    "\n",
    "\n",
    "#-------------------------------------#\n",
    "# MODEL EXPORT HELPER FUNCTIONS\n",
    "#-------------------------------------#\n",
    "\n",
    "def matrix_to_json(matrix):\n",
    "    df = pd.DataFrame(matrix.apply(lambda row: row.to_json(), axis=1), columns = ['data_col'])\n",
    "    df['local_id'] = df.index\n",
    "    return df\n",
    "\n",
    "\n",
    "def export_content_cosine_similarity (similarity_matrix):\n",
    "    df = matrix_to_json(similarity_matrix)\n",
    "    sql = export_content_cosine_similarity_query()\n",
    "    export_data(df, sql)\n",
    "\n",
    "\n",
    "def export_title_similarity (similarity_matrix):\n",
    "    df = matrix_to_json(similarity_matrix)\n",
    "    sql = export_title_similarity_query()\n",
    "    export_data(df, sql)\n",
    "\n",
    "\n",
    "def export_cat_tags_similarity (similarity_matrix):\n",
    "    df = matrix_to_json(similarity_matrix)\n",
    "    sql = export_cat_tags_similarity_query()\n",
    "    export_data(df, sql)\n",
    "\n",
    "\n",
    "def export_content_angles(angles):\n",
    "    df = matrix_to_json(angles)\n",
    "    sql = export_content_angles_query()\n",
    "    export_data(df, sql)\n",
    "\n",
    "\n",
    "def export_content_distance(distance):\n",
    "    df = matrix_to_json(distance)\n",
    "    sql = export_content_distance_query()\n",
    "    export_data(df, sql)\n",
    "\n",
    "\n",
    "def export_ts_ss(ts_ss_sim_matrix):\n",
    "    df = matrix_to_json(ts_ss_sim_matrix)\n",
    "    sql = export_ts_ss_query()\n",
    "    export_data(df, sql)\n",
    "    \n",
    "\n",
    "# def export_content_magnitude(vector_size):\n",
    "#     df = matrix_to_json(vector_size)\n",
    "#     df['local_id'] = df.index\n",
    "#     sql = export_content_magnitude_query()\n",
    "#     export_data(df, sql)\n",
    "\n",
    "\n",
    "#-------------------------------------#\n",
    "# MODEL CREATE DRIVER\n",
    "#-------------------------------------#\n",
    "\n",
    "\n",
    "truncate_similarities()\n",
    "article_master = import_content()\n",
    "\n",
    "\n",
    "\n",
    "## PREPROCESS CONTENT\n",
    "print(\"Previous Model Truncated.\")\n",
    "print(\"Pre-processing....\")\n",
    "\n",
    "\n",
    "# REDUCE CONTENT:\n",
    "article_master['reduced_content'] = article_master.apply\\\n",
    "    (lambda row: re.sub('[^a-z\\s]', '',filter_html(row.bodytext).lower()), axis = 1)\n",
    "\n",
    "#-- Potential Global Variable\n",
    "\n",
    "snowball = Porter2Stemmer()\n",
    "\n",
    "article_master['stemmed_content'] = article_master.apply\\\n",
    "    (lambda row: text_stemmer(row.reduced_content, snowball), axis = 1)\n",
    "\n",
    "article_master['stemmed_content'] = article_master['stemmed_content'].fillna('')\n",
    "\n",
    "\n",
    "\n",
    "# REDUCE TITLE:\n",
    "# It must be noted that numbers are removed from the content and not from the title\n",
    "article_master['reduced_title'] = article_master.apply\\\n",
    "    (lambda row: re.sub('[^a-z0-9\\s]', '',row.title.lower()), axis = 1)\n",
    "\n",
    "article_master['stemmed_title'] = article_master.apply\\\n",
    "    (lambda row: text_stemmer(row.reduced_title, snowball), axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "# REDUCE TAGS AND CATEGORY\n",
    "article_master['reduced_category'] = article_master['category'].apply(clean_tags)\n",
    "article_master['reduced_tags'] = article_master['tags'].apply(clean_tags)\n",
    "article_master[\"meta_soup\"] = article_master[\"reduced_category\"] + ' ' + article_master['reduced_tags']\n",
    "\n",
    "\n",
    "\n",
    "#-------------------------------------#\n",
    "## Preprocess Content - End\n",
    "#-------------------------------------#\n",
    "\n",
    "print(\"Creating new Model.\")\n",
    "\n",
    "# MODEL CREATION\n",
    "\n",
    "# Define a TF-IDF Vectorizer Object for Un-normalised TF-IDF vectors\n",
    "# Remove all english stop words such as 'the', 'a'\n",
    "\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words = 'english', norm = None)\n",
    "tfidf_vectors = tfidf.fit_transform(article_master['stemmed_content'])\n",
    "\n",
    "\n",
    "cosine_sim_content = cosine_similarity(tfidf_vectors)\n",
    "\n",
    "# Export content similarity matrix\n",
    "df = pd.DataFrame.from_records(cosine_sim_content)\n",
    "export_content_cosine_similarity(df)\n",
    "print(\"Exported Content Cosine Similarity Matrix .\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Theta, Euclidean Distance and Magnitude of TF-IDF vectors: required for TS-SS similarity\n",
    "angles = theta(cosine_sim_content)\n",
    "euclidean_distance = euclidean(tfidf_vectors)\n",
    "magnitude , magnitude_diff = magnitude_and_difference(tfidf_vectors)\n",
    "ed_md_square = np.square(euclidean_distance + magnitude_diff)\n",
    "magnitude_product = linear_kernel(magnitude)\n",
    "sine_theta = np.sin(angles)\n",
    "const = (0.5 * np.pi) * 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_ss = np.multiply(magnitude_product, sine_theta, ed_md_square) * const\n",
    "ts_ss = np.multiply(ts_ss,angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2819.2781284 , 8595.61338851, 7875.20827602, ..., 3055.09822383,\n",
       "        5119.41291591, 2838.21771892],\n",
       "       [8595.61338851,  794.10494635, 4193.02756793, ..., 1602.56141323,\n",
       "        2687.46201332, 1505.93579739],\n",
       "       [7875.20827602, 4193.02756793,  668.91401554, ..., 1471.08587   ,\n",
       "        2467.29008247, 1379.9065406 ],\n",
       "       ...,\n",
       "       [3055.09822383, 1602.56141323, 1471.08587   , ...,  100.09895524,\n",
       "         960.82165951,  535.38636496],\n",
       "       [5119.41291591, 2687.46201332, 2467.29008247, ...,  960.82165951,\n",
       "         280.31320494,  882.39459279],\n",
       "       [2838.21771892, 1505.93579739, 1379.9065406 , ...,  535.38636496,\n",
       "         882.39459279,   86.74829375]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(magnitude_product, sine_theta, ed_md_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 278251.8236124 , 7974746.35382974, 7402850.1815568 , ...,\n",
       "        2803626.14297745, 4547149.03996498, 2388520.65091326],\n",
       "       [7974746.35382974,   78375.01673392, 3619515.77375172, ...,\n",
       "        1569601.77131938, 2611487.97247238, 1410553.4792661 ],\n",
       "       [7402850.1815568 , 3619515.77375172,   66019.22058976, ...,\n",
       "        1439916.44121214, 2394670.92737099, 1305878.27714038],\n",
       "       ...,\n",
       "       [2803626.14297745, 1569601.77131938, 1439916.44121214, ...,\n",
       "           9879.37089189,  901835.10893707,  496179.20788944],\n",
       "       [4547149.03996498, 2611487.97247238, 2394670.92737099, ...,\n",
       "         901835.10893707,   27665.82682005,  690607.03333477],\n",
       "       [2388520.65091326, 1410553.4792661 , 1305878.27714038, ...,\n",
       "         496179.20788944,  690607.03333477,    8561.72035283]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    INSERT INTO `recen_magnitude_content` (`local_id`, `magnitude_diff_square`)\\n    VALUES(%s, %s)\\n    '"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_content_magnitude_query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'export_ts_ss_query' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-0bfac5181e1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Export Ts_ss similarity matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts_ss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mexport_ts_ss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Export Theta matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-f53f1f3c40a0>\u001b[0m in \u001b[0;36mexport_ts_ss\u001b[0;34m(ts_ss_sim_matrix)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexport_ts_ss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts_ss_sim_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix_to_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts_ss_sim_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0msql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexport_ts_ss_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0mexport_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msql\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'export_ts_ss_query' is not defined"
     ]
    }
   ],
   "source": [
    "# Export Ts_ss similarity matrix\n",
    "df = pd.DataFrame.from_records(ts_ss)\n",
    "export_ts_ss(df)\n",
    "\n",
    "\n",
    "# Export Theta matrix\n",
    "df = pd.DataFrame.from_records(angles)\n",
    "export_content_angles(df)\n",
    "\n",
    "# Export Euclidean Distance  matrix\n",
    "df = pd.DataFrame.from_records(euclidean_distance)\n",
    "export_content_distance(df)\n",
    "\n",
    "# Export Vector Magnitudes\n",
    "# df = pd.DataFrame.from_records(diff_squares)\n",
    "# export_content_magnitude(df)\n",
    "\n",
    "print(\"Exported Content TS-SS Similarity Matrices .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define a TF-IDF Vectorizer Object for normalised TF-IDF vectors\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix_title = tfidf.fit_transform(article_master['stemmed_title'])\n",
    "cosine_sim_title = linear_kernel(tfidf_matrix_title, tfidf_matrix_title)\n",
    "\n",
    "# Export title similarity matrix\n",
    "df = pd.DataFrame.from_records(cosine_sim_title)\n",
    "export_title_similarity(df)\n",
    "print(\"Exported Title Cosine Similarity Matrix .\")\n",
    "\n",
    "\n",
    "\n",
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(article_master[\"meta_soup\"])\n",
    "cosine_sim_cat_tags = cosine_similarity(count_matrix, count_matrix)\n",
    "\n",
    "# Export title similarity matrix\n",
    "df = pd.DataFrame.from_records(cosine_sim_cat_tags)\n",
    "export_cat_tags_similarity(df)\n",
    "print(\"Exported Tags/Category Cosine Similarity Matrix .\")\n",
    "\n",
    "\n",
    "article_map = (article_master[['article_id','title']].copy()).drop_duplicates()\n",
    "article_map['local_id'] = article_map.index\n",
    "\n",
    "# Export article_map\n",
    "export_map(article_map)\n",
    "\n",
    "print(\"Model Created\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
