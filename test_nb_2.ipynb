{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TfIdfVectorizer from scikit-learn for text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# Import CountVectorizer to create count matrix for tags\n",
    "# This is an alternative to tfidf\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "# Requried to tokenise the text before Stemming\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "# from nltk.stem import PorterStemmer\n",
    "from porter2stemmer import Porter2Stemmer\n",
    "\n",
    "# Import linear_kernel for Cosine Similarity calculation of bodytext and title\n",
    "# This wil be applied on a tfidf matrix and NOT a count matrix\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Compute the Cosine Similarity matrix based on a count_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "\n",
    "# Funtions interacting with the database\n",
    "from db_functions import *\n",
    "\n",
    "# DB Queries generated in here\n",
    "from queries import *\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------#\n",
    "# MODEL CREATE HELPER FUNCTIONS\n",
    "#-------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "def filter_html(text):\n",
    "    soup = BeautifulSoup(text, features=\"html5lib\")\n",
    "    # text = re.sub('[^a-z\\s]', '',soup.get_text(separator=' ').lower())\n",
    "    text = soup.get_text(separator=' ')\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "def text_stemmer (txt, stemmer):\n",
    "    token_words=word_tokenize(txt)\n",
    "    stem_sentence=[]\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(stemmer.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)\n",
    "\n",
    "\n",
    "\n",
    "def clean_tags(x):\n",
    "    if isinstance(x, str):\n",
    "        return str.lower(x.replace(\" \", \"\")).replace(\",\",\" \")\n",
    "\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#-------------------------------------#\n",
    "# MODEL EXPORT HELPER FUNCTIONS\n",
    "#-------------------------------------#\n",
    "\n",
    "def matrix_to_jason(matrix):\n",
    "    df = pd.DataFrame(matrix.apply(lambda row: row.to_json(), axis=1), columns = ['jsol_col'])\n",
    "    df['local_id'] = df.index\n",
    "    return df\n",
    "\n",
    "\n",
    "def export_content_similarity (similarity_matrix):\n",
    "    df = matrix_to_jason(similarity_matrix)\n",
    "    sql = export_content_similarity_query()\n",
    "    export_data(df, sql)\n",
    "\n",
    "\n",
    "def export_title_similarity (similarity_matrix):\n",
    "    df = matrix_to_jason(similarity_matrix)\n",
    "    sql = export_title_similarity_query()\n",
    "    export_data(df, sql)\n",
    "\n",
    "\n",
    "def export_cat_tags_similarity (similarity_matrix):\n",
    "    df = matrix_to_jason(similarity_matrix)\n",
    "    sql = export_cat_tags_similarity_query()\n",
    "    export_data(df, sql)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySQL connection is closed\n",
      "MySQL connection is closed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#-- At this point the newly stemmed metadata content can be written to the database.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-------------------------------------#\n",
    "# MODEL CREATE DRIVER\n",
    "#-------------------------------------#\n",
    "\n",
    "\n",
    "truncate_similarities()\n",
    "article_master = import_content()\n",
    "\n",
    "\n",
    "\n",
    "## PREPROCESS CONTENT\n",
    "\n",
    "\n",
    "\n",
    "# REDUCE CONTENT:\n",
    "article_master['reduced_content'] = article_master.apply\\\n",
    "    (lambda row: re.sub('[^a-z\\s]', '',filter_html(row.bodytext).lower()), axis = 1)\n",
    "\n",
    "#-- Potential Global Variable\n",
    "\n",
    "# porter = PorterStemmer()\n",
    "snowball = Porter2Stemmer()\n",
    "\n",
    "article_master['stemmed_content'] = article_master.apply\\\n",
    "    (lambda row: text_stemmer(row.reduced_content, snowball), axis = 1)\n",
    "\n",
    "article_master['stemmed_content'] = article_master['stemmed_content'].fillna('')\n",
    "\n",
    "\n",
    "\n",
    "# REDUCE TITLE:\n",
    "# It must be noted that numbers are removed from the content and not from the title\n",
    "article_master['reduced_title'] = article_master.apply\\\n",
    "    (lambda row: re.sub('[^a-z0-9\\s]', '',row.title.lower()), axis = 1)\n",
    "\n",
    "article_master['stemmed_title'] = article_master.apply\\\n",
    "    (lambda row: text_stemmer(row.reduced_title, snowball), axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "# REDUCE TAGS AND CATEGORY\n",
    "article_master['reduced_category'] = article_master['category'].apply(clean_tags)\n",
    "article_master['reduced_tags'] = article_master['tags'].apply(clean_tags)\n",
    "article_master[\"meta_soup\"] = article_master[\"reduced_category\"] + ' ' + article_master['reduced_tags']\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#-- At this point the newly stemmed metadata content can be written to the database.\n",
    "\"\"\"\n",
    "\n",
    "#-------------------------------------#\n",
    "## Preprocess Content - End\n",
    "#-------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "\n",
    "def get_theta(cosine_similarity):\n",
    "    sim = np.divide(np.trunc(np.multiply(cosine_similarity, 100000000000000)), 100000000000000)\n",
    "    angles = np.arccos(sim) + math.radians(10)\n",
    "    return angles\n",
    "\n",
    "def get_magnitude(matrix):\n",
    "    magnitude = np.sqrt(matrix.multiply(matrix).sum(1))\n",
    "    return magnitude\n",
    "\n",
    "\n",
    "def get_euclidean(vectors):\n",
    "    magnitudes = euclidean_distances(vectors)\n",
    "    return magnitudes    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tfidf = TfidfVectorizer(stop_words = 'english', norm = None)\n",
    "tfidf_vectors = tfidf.fit_transform(article_master['stemmed_content'])\n",
    "# TO-DO: Write vectors to the db.\n",
    "\n",
    "\n",
    "cosine_sim_content = cosine_similarity(tfidf_vectors)\n",
    "angles = get_theta(cosine_sim_content)\n",
    "# TO-DO: Write theta values to the db.\n",
    "\n",
    "vector_size = get_magnitude(tfidf_vectors)\n",
    "# TO-DO: Write vector_size values to the db.\n",
    "\n",
    "\n",
    "euclidean_distance = get_euclidean(tfidf_vectors)\n",
    "# TO-DO: Write euclidean_distance values to the db.\n",
    "\n",
    "# This completes model creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ts_ss_similarity():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<410x1 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 410 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_triangle_similarity(magnitude, angles):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.        , 137.86974857, 137.0264865 , ..., 126.74526777,\n",
       "        126.77152799, 123.63912415],\n",
       "       [137.86974857,   0.        ,  81.25884899, ...,  71.4583223 ,\n",
       "         77.72380463,  69.31166048],\n",
       "       [137.0264865 ,  81.25884899,   0.        , ...,  66.22403245,\n",
       "         72.95078988,  64.44082863],\n",
       "       ...,\n",
       "       [126.74526777,  71.4583223 ,  66.22403245, ...,   0.        ,\n",
       "         45.01046088,  31.01588147],\n",
       "       [126.77152799,  77.72380463,  72.95078988, ...,  45.01046088,\n",
       "          0.        ,  38.45708066],\n",
       "       [123.63912415,  69.31166048,  64.44082863, ...,  31.01588147,\n",
       "         38.45708066,   0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_euclidean(tfidf_vectors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
